# -*- coding: utf-8 -*-
"""Tarefa_S15.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zy-VA54rHSTzyP_TrR0vsp7GKt2DFcZ5
"""

!pip install PySpark

import pyspark
from pyspark.sql import SparkSession
from pyspark import SparkFiles

spark = SparkSession.builder.appName("RealEstate").master("local[*]").getOrCreate()
sc = spark.sparkContext

rdd = sc.textFile("RealEstate.csv")

#tarefa

#pegando somente quantidade quartos, pre√ßo
rdd = rdd.filter(lambda x: x.split(",")[3]!= "Bedrooms")

pairRDD = rdd.map(lambda x: ( int(x.split(",")[3]), (float(x.split(",")[6]), 1) ))
pairRDD.take(5)

#contagem
count = pairRDD.reduceByKey(lambda x,y:(x[0]+ y[0], x[1]+ y[1]) )
count.take(5)

finalrdd = count.mapValues(lambda x: x[0]/x[1])

final_sorted = finalrdd.sortBy(lambda x: x[1], ascending=True)

final_sorted.coalesce(1).saveAsTextFile("tarefa15_unique.txt")